{
  "best_global_step": 4540,
  "best_metric": 0.09008360654115677,
  "best_model_checkpoint": "/nethome/hhelbig/Neural_Networks/LLM_tuning/llama_test/checkpoint-4540",
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 4540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004405286343612335,
      "grad_norm": 0.7993443012237549,
      "learning_rate": 2e-05,
      "loss": 1.7955,
      "step": 1
    },
    {
      "epoch": 0.04405286343612335,
      "grad_norm": 0.7887394428253174,
      "learning_rate": 1.996035242290749e-05,
      "loss": 1.7605,
      "step": 10
    },
    {
      "epoch": 0.0881057268722467,
      "grad_norm": 0.7303516268730164,
      "learning_rate": 1.991629955947137e-05,
      "loss": 1.6807,
      "step": 20
    },
    {
      "epoch": 0.13215859030837004,
      "grad_norm": 0.7087792158126831,
      "learning_rate": 1.9872246696035245e-05,
      "loss": 1.6091,
      "step": 30
    },
    {
      "epoch": 0.1762114537444934,
      "grad_norm": 0.7545689940452576,
      "learning_rate": 1.982819383259912e-05,
      "loss": 1.542,
      "step": 40
    },
    {
      "epoch": 0.22026431718061673,
      "grad_norm": 0.807420551776886,
      "learning_rate": 1.9784140969162998e-05,
      "loss": 1.455,
      "step": 50
    },
    {
      "epoch": 0.2643171806167401,
      "grad_norm": 0.9217675924301147,
      "learning_rate": 1.9740088105726874e-05,
      "loss": 1.3495,
      "step": 60
    },
    {
      "epoch": 0.30837004405286345,
      "grad_norm": 1.0486518144607544,
      "learning_rate": 1.969603524229075e-05,
      "loss": 1.2169,
      "step": 70
    },
    {
      "epoch": 0.3524229074889868,
      "grad_norm": 1.3490068912506104,
      "learning_rate": 1.9651982378854627e-05,
      "loss": 1.0878,
      "step": 80
    },
    {
      "epoch": 0.3964757709251101,
      "grad_norm": 1.4060978889465332,
      "learning_rate": 1.9607929515418503e-05,
      "loss": 0.9531,
      "step": 90
    },
    {
      "epoch": 0.44052863436123346,
      "grad_norm": 2.3057608604431152,
      "learning_rate": 1.956387665198238e-05,
      "loss": 0.8006,
      "step": 100
    },
    {
      "epoch": 0.4845814977973568,
      "grad_norm": 2.063408136367798,
      "learning_rate": 1.9519823788546256e-05,
      "loss": 0.6668,
      "step": 110
    },
    {
      "epoch": 0.5286343612334802,
      "grad_norm": 1.5616114139556885,
      "learning_rate": 1.9475770925110132e-05,
      "loss": 0.5367,
      "step": 120
    },
    {
      "epoch": 0.5726872246696035,
      "grad_norm": 1.6722031831741333,
      "learning_rate": 1.943171806167401e-05,
      "loss": 0.4589,
      "step": 130
    },
    {
      "epoch": 0.6167400881057269,
      "grad_norm": 1.9495899677276611,
      "learning_rate": 1.9387665198237885e-05,
      "loss": 0.3828,
      "step": 140
    },
    {
      "epoch": 0.6607929515418502,
      "grad_norm": 2.1274940967559814,
      "learning_rate": 1.9343612334801765e-05,
      "loss": 0.3464,
      "step": 150
    },
    {
      "epoch": 0.7048458149779736,
      "grad_norm": 1.2120321989059448,
      "learning_rate": 1.929955947136564e-05,
      "loss": 0.3226,
      "step": 160
    },
    {
      "epoch": 0.748898678414097,
      "grad_norm": 1.2793816328048706,
      "learning_rate": 1.9255506607929517e-05,
      "loss": 0.2932,
      "step": 170
    },
    {
      "epoch": 0.7929515418502202,
      "grad_norm": 2.022188901901245,
      "learning_rate": 1.9211453744493394e-05,
      "loss": 0.2825,
      "step": 180
    },
    {
      "epoch": 0.8370044052863436,
      "grad_norm": 1.6075507402420044,
      "learning_rate": 1.916740088105727e-05,
      "loss": 0.2704,
      "step": 190
    },
    {
      "epoch": 0.8810572687224669,
      "grad_norm": 1.5302058458328247,
      "learning_rate": 1.9123348017621147e-05,
      "loss": 0.267,
      "step": 200
    },
    {
      "epoch": 0.9251101321585903,
      "grad_norm": 1.8334640264511108,
      "learning_rate": 1.9079295154185026e-05,
      "loss": 0.246,
      "step": 210
    },
    {
      "epoch": 0.9691629955947136,
      "grad_norm": 1.4615422487258911,
      "learning_rate": 1.90352422907489e-05,
      "loss": 0.2365,
      "step": 220
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.21602052450180054,
      "eval_runtime": 27.9923,
      "eval_samples_per_second": 7.216,
      "eval_steps_per_second": 0.929,
      "step": 227
    },
    {
      "epoch": 1.013215859030837,
      "grad_norm": 1.7084306478500366,
      "learning_rate": 1.8991189427312776e-05,
      "loss": 0.2218,
      "step": 230
    },
    {
      "epoch": 1.0572687224669604,
      "grad_norm": 1.7181041240692139,
      "learning_rate": 1.8947136563876652e-05,
      "loss": 0.2272,
      "step": 240
    },
    {
      "epoch": 1.1013215859030836,
      "grad_norm": 1.9074715375900269,
      "learning_rate": 1.890308370044053e-05,
      "loss": 0.213,
      "step": 250
    },
    {
      "epoch": 1.145374449339207,
      "grad_norm": 1.4252227544784546,
      "learning_rate": 1.8859030837004405e-05,
      "loss": 0.2039,
      "step": 260
    },
    {
      "epoch": 1.1894273127753303,
      "grad_norm": 1.3691256046295166,
      "learning_rate": 1.881497797356828e-05,
      "loss": 0.189,
      "step": 270
    },
    {
      "epoch": 1.2334801762114538,
      "grad_norm": 1.97701895236969,
      "learning_rate": 1.877092511013216e-05,
      "loss": 0.1874,
      "step": 280
    },
    {
      "epoch": 1.277533039647577,
      "grad_norm": 1.8665999174118042,
      "learning_rate": 1.8726872246696037e-05,
      "loss": 0.1949,
      "step": 290
    },
    {
      "epoch": 1.3215859030837005,
      "grad_norm": 1.694823980331421,
      "learning_rate": 1.8682819383259914e-05,
      "loss": 0.1845,
      "step": 300
    },
    {
      "epoch": 1.3656387665198237,
      "grad_norm": 1.958382248878479,
      "learning_rate": 1.863876651982379e-05,
      "loss": 0.1827,
      "step": 310
    },
    {
      "epoch": 1.4096916299559472,
      "grad_norm": 1.5311697721481323,
      "learning_rate": 1.8594713656387666e-05,
      "loss": 0.1719,
      "step": 320
    },
    {
      "epoch": 1.4537444933920705,
      "grad_norm": 1.7711678743362427,
      "learning_rate": 1.8550660792951543e-05,
      "loss": 0.1609,
      "step": 330
    },
    {
      "epoch": 1.497797356828194,
      "grad_norm": 1.5742900371551514,
      "learning_rate": 1.8506607929515422e-05,
      "loss": 0.1719,
      "step": 340
    },
    {
      "epoch": 1.5418502202643172,
      "grad_norm": 1.4349017143249512,
      "learning_rate": 1.84625550660793e-05,
      "loss": 0.1645,
      "step": 350
    },
    {
      "epoch": 1.5859030837004404,
      "grad_norm": 1.2569714784622192,
      "learning_rate": 1.8418502202643175e-05,
      "loss": 0.1617,
      "step": 360
    },
    {
      "epoch": 1.6299559471365639,
      "grad_norm": 1.3799022436141968,
      "learning_rate": 1.837444933920705e-05,
      "loss": 0.1619,
      "step": 370
    },
    {
      "epoch": 1.6740088105726874,
      "grad_norm": 1.7009317874908447,
      "learning_rate": 1.8330396475770928e-05,
      "loss": 0.158,
      "step": 380
    },
    {
      "epoch": 1.7180616740088106,
      "grad_norm": 1.4545713663101196,
      "learning_rate": 1.8286343612334804e-05,
      "loss": 0.1583,
      "step": 390
    },
    {
      "epoch": 1.7621145374449338,
      "grad_norm": 1.3410032987594604,
      "learning_rate": 1.824229074889868e-05,
      "loss": 0.1535,
      "step": 400
    },
    {
      "epoch": 1.8061674008810573,
      "grad_norm": 1.6894608736038208,
      "learning_rate": 1.8198237885462557e-05,
      "loss": 0.1557,
      "step": 410
    },
    {
      "epoch": 1.8502202643171806,
      "grad_norm": 1.4105182886123657,
      "learning_rate": 1.8154185022026433e-05,
      "loss": 0.1419,
      "step": 420
    },
    {
      "epoch": 1.894273127753304,
      "grad_norm": 1.4004212617874146,
      "learning_rate": 1.811013215859031e-05,
      "loss": 0.149,
      "step": 430
    },
    {
      "epoch": 1.9383259911894273,
      "grad_norm": 1.4742121696472168,
      "learning_rate": 1.8066079295154186e-05,
      "loss": 0.146,
      "step": 440
    },
    {
      "epoch": 1.9823788546255505,
      "grad_norm": 1.3798760175704956,
      "learning_rate": 1.8022026431718062e-05,
      "loss": 0.1388,
      "step": 450
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.1323910355567932,
      "eval_runtime": 27.8834,
      "eval_samples_per_second": 7.244,
      "eval_steps_per_second": 0.932,
      "step": 454
    },
    {
      "epoch": 2.026431718061674,
      "grad_norm": 1.231076955795288,
      "learning_rate": 1.797797356828194e-05,
      "loss": 0.1351,
      "step": 460
    },
    {
      "epoch": 2.0704845814977975,
      "grad_norm": 1.2675548791885376,
      "learning_rate": 1.793392070484582e-05,
      "loss": 0.1322,
      "step": 470
    },
    {
      "epoch": 2.1145374449339207,
      "grad_norm": 1.5910168886184692,
      "learning_rate": 1.7889867841409695e-05,
      "loss": 0.1344,
      "step": 480
    },
    {
      "epoch": 2.158590308370044,
      "grad_norm": 1.5249488353729248,
      "learning_rate": 1.784581497797357e-05,
      "loss": 0.1459,
      "step": 490
    },
    {
      "epoch": 2.202643171806167,
      "grad_norm": 1.5248072147369385,
      "learning_rate": 1.7801762114537447e-05,
      "loss": 0.1445,
      "step": 500
    },
    {
      "epoch": 2.246696035242291,
      "grad_norm": 1.4320141077041626,
      "learning_rate": 1.7757709251101324e-05,
      "loss": 0.1327,
      "step": 510
    },
    {
      "epoch": 2.290748898678414,
      "grad_norm": 1.276271939277649,
      "learning_rate": 1.77136563876652e-05,
      "loss": 0.131,
      "step": 520
    },
    {
      "epoch": 2.3348017621145374,
      "grad_norm": 1.7809169292449951,
      "learning_rate": 1.7669603524229077e-05,
      "loss": 0.1234,
      "step": 530
    },
    {
      "epoch": 2.3788546255506606,
      "grad_norm": 1.3212989568710327,
      "learning_rate": 1.7625550660792953e-05,
      "loss": 0.1263,
      "step": 540
    },
    {
      "epoch": 2.4229074889867843,
      "grad_norm": 1.1778836250305176,
      "learning_rate": 1.758149779735683e-05,
      "loss": 0.1314,
      "step": 550
    },
    {
      "epoch": 2.4669603524229076,
      "grad_norm": 1.515047311782837,
      "learning_rate": 1.7537444933920706e-05,
      "loss": 0.129,
      "step": 560
    },
    {
      "epoch": 2.511013215859031,
      "grad_norm": 1.1689980030059814,
      "learning_rate": 1.7493392070484582e-05,
      "loss": 0.1317,
      "step": 570
    },
    {
      "epoch": 2.555066079295154,
      "grad_norm": 1.3769735097885132,
      "learning_rate": 1.744933920704846e-05,
      "loss": 0.119,
      "step": 580
    },
    {
      "epoch": 2.5991189427312777,
      "grad_norm": 1.6432005167007446,
      "learning_rate": 1.7405286343612335e-05,
      "loss": 0.1278,
      "step": 590
    },
    {
      "epoch": 2.643171806167401,
      "grad_norm": 1.400353193283081,
      "learning_rate": 1.7361233480176214e-05,
      "loss": 0.1227,
      "step": 600
    },
    {
      "epoch": 2.6872246696035242,
      "grad_norm": 1.3098880052566528,
      "learning_rate": 1.731718061674009e-05,
      "loss": 0.1225,
      "step": 610
    },
    {
      "epoch": 2.7312775330396475,
      "grad_norm": 1.2165284156799316,
      "learning_rate": 1.7273127753303967e-05,
      "loss": 0.1278,
      "step": 620
    },
    {
      "epoch": 2.7753303964757707,
      "grad_norm": 1.3369587659835815,
      "learning_rate": 1.7229074889867843e-05,
      "loss": 0.1217,
      "step": 630
    },
    {
      "epoch": 2.8193832599118944,
      "grad_norm": 1.1183421611785889,
      "learning_rate": 1.718502202643172e-05,
      "loss": 0.1195,
      "step": 640
    },
    {
      "epoch": 2.8634361233480177,
      "grad_norm": 1.26302170753479,
      "learning_rate": 1.7140969162995596e-05,
      "loss": 0.1188,
      "step": 650
    },
    {
      "epoch": 2.907488986784141,
      "grad_norm": 1.4292961359024048,
      "learning_rate": 1.7096916299559473e-05,
      "loss": 0.1221,
      "step": 660
    },
    {
      "epoch": 2.951541850220264,
      "grad_norm": 1.360859990119934,
      "learning_rate": 1.705286343612335e-05,
      "loss": 0.1227,
      "step": 670
    },
    {
      "epoch": 2.995594713656388,
      "grad_norm": 1.126701831817627,
      "learning_rate": 1.7008810572687225e-05,
      "loss": 0.1184,
      "step": 680
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.11517932265996933,
      "eval_runtime": 27.9057,
      "eval_samples_per_second": 7.239,
      "eval_steps_per_second": 0.932,
      "step": 681
    },
    {
      "epoch": 3.039647577092511,
      "grad_norm": 1.4070038795471191,
      "learning_rate": 1.69647577092511e-05,
      "loss": 0.1183,
      "step": 690
    },
    {
      "epoch": 3.0837004405286343,
      "grad_norm": 1.1106367111206055,
      "learning_rate": 1.6920704845814978e-05,
      "loss": 0.1201,
      "step": 700
    },
    {
      "epoch": 3.1277533039647576,
      "grad_norm": 1.3411043882369995,
      "learning_rate": 1.6876651982378854e-05,
      "loss": 0.1178,
      "step": 710
    },
    {
      "epoch": 3.171806167400881,
      "grad_norm": 1.1894497871398926,
      "learning_rate": 1.683259911894273e-05,
      "loss": 0.118,
      "step": 720
    },
    {
      "epoch": 3.2158590308370045,
      "grad_norm": 1.1282672882080078,
      "learning_rate": 1.678854625550661e-05,
      "loss": 0.1096,
      "step": 730
    },
    {
      "epoch": 3.2599118942731278,
      "grad_norm": 1.4342365264892578,
      "learning_rate": 1.6744493392070487e-05,
      "loss": 0.1216,
      "step": 740
    },
    {
      "epoch": 3.303964757709251,
      "grad_norm": 1.2035324573516846,
      "learning_rate": 1.6700440528634363e-05,
      "loss": 0.1142,
      "step": 750
    },
    {
      "epoch": 3.3480176211453743,
      "grad_norm": 1.1673718690872192,
      "learning_rate": 1.665638766519824e-05,
      "loss": 0.1171,
      "step": 760
    },
    {
      "epoch": 3.392070484581498,
      "grad_norm": 1.3210139274597168,
      "learning_rate": 1.6612334801762116e-05,
      "loss": 0.1173,
      "step": 770
    },
    {
      "epoch": 3.436123348017621,
      "grad_norm": 1.2718487977981567,
      "learning_rate": 1.6568281938325992e-05,
      "loss": 0.1108,
      "step": 780
    },
    {
      "epoch": 3.4801762114537445,
      "grad_norm": 1.1721601486206055,
      "learning_rate": 1.652422907488987e-05,
      "loss": 0.1108,
      "step": 790
    },
    {
      "epoch": 3.5242290748898677,
      "grad_norm": 1.220628023147583,
      "learning_rate": 1.648017621145375e-05,
      "loss": 0.1191,
      "step": 800
    },
    {
      "epoch": 3.568281938325991,
      "grad_norm": 1.308838963508606,
      "learning_rate": 1.643612334801762e-05,
      "loss": 0.1296,
      "step": 810
    },
    {
      "epoch": 3.6123348017621146,
      "grad_norm": 1.262461543083191,
      "learning_rate": 1.6392070484581498e-05,
      "loss": 0.1176,
      "step": 820
    },
    {
      "epoch": 3.656387665198238,
      "grad_norm": 0.9874207377433777,
      "learning_rate": 1.6348017621145374e-05,
      "loss": 0.1065,
      "step": 830
    },
    {
      "epoch": 3.700440528634361,
      "grad_norm": 0.9818394184112549,
      "learning_rate": 1.630396475770925e-05,
      "loss": 0.1114,
      "step": 840
    },
    {
      "epoch": 3.744493392070485,
      "grad_norm": 1.169972538948059,
      "learning_rate": 1.6259911894273127e-05,
      "loss": 0.1219,
      "step": 850
    },
    {
      "epoch": 3.788546255506608,
      "grad_norm": 1.2433679103851318,
      "learning_rate": 1.6215859030837006e-05,
      "loss": 0.1108,
      "step": 860
    },
    {
      "epoch": 3.8325991189427313,
      "grad_norm": 1.5237606763839722,
      "learning_rate": 1.6171806167400883e-05,
      "loss": 0.1135,
      "step": 870
    },
    {
      "epoch": 3.8766519823788546,
      "grad_norm": 1.1642134189605713,
      "learning_rate": 1.612775330396476e-05,
      "loss": 0.1161,
      "step": 880
    },
    {
      "epoch": 3.920704845814978,
      "grad_norm": 1.4809848070144653,
      "learning_rate": 1.6083700440528636e-05,
      "loss": 0.1126,
      "step": 890
    },
    {
      "epoch": 3.964757709251101,
      "grad_norm": 1.214215874671936,
      "learning_rate": 1.6039647577092512e-05,
      "loss": 0.1148,
      "step": 900
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.10791351646184921,
      "eval_runtime": 27.8563,
      "eval_samples_per_second": 7.252,
      "eval_steps_per_second": 0.933,
      "step": 908
    },
    {
      "epoch": 4.008810572687224,
      "grad_norm": 1.0164138078689575,
      "learning_rate": 1.5995594713656388e-05,
      "loss": 0.1091,
      "step": 910
    },
    {
      "epoch": 4.052863436123348,
      "grad_norm": 1.0023469924926758,
      "learning_rate": 1.5951541850220265e-05,
      "loss": 0.1098,
      "step": 920
    },
    {
      "epoch": 4.096916299559472,
      "grad_norm": 1.0819873809814453,
      "learning_rate": 1.5907488986784144e-05,
      "loss": 0.1105,
      "step": 930
    },
    {
      "epoch": 4.140969162995595,
      "grad_norm": 1.1572842597961426,
      "learning_rate": 1.586343612334802e-05,
      "loss": 0.1193,
      "step": 940
    },
    {
      "epoch": 4.185022026431718,
      "grad_norm": 1.1035219430923462,
      "learning_rate": 1.5819383259911897e-05,
      "loss": 0.1202,
      "step": 950
    },
    {
      "epoch": 4.229074889867841,
      "grad_norm": 1.5299608707427979,
      "learning_rate": 1.5775330396475773e-05,
      "loss": 0.1163,
      "step": 960
    },
    {
      "epoch": 4.273127753303965,
      "grad_norm": 1.3242682218551636,
      "learning_rate": 1.573127753303965e-05,
      "loss": 0.1117,
      "step": 970
    },
    {
      "epoch": 4.317180616740088,
      "grad_norm": 1.1718719005584717,
      "learning_rate": 1.5687224669603526e-05,
      "loss": 0.1121,
      "step": 980
    },
    {
      "epoch": 4.361233480176211,
      "grad_norm": 1.0486115217208862,
      "learning_rate": 1.5643171806167403e-05,
      "loss": 0.1104,
      "step": 990
    },
    {
      "epoch": 4.405286343612334,
      "grad_norm": 1.226507306098938,
      "learning_rate": 1.559911894273128e-05,
      "loss": 0.1056,
      "step": 1000
    },
    {
      "epoch": 4.4493392070484585,
      "grad_norm": 1.3383630514144897,
      "learning_rate": 1.5555066079295155e-05,
      "loss": 0.1022,
      "step": 1010
    },
    {
      "epoch": 4.493392070484582,
      "grad_norm": 1.0742061138153076,
      "learning_rate": 1.551101321585903e-05,
      "loss": 0.1008,
      "step": 1020
    },
    {
      "epoch": 4.537444933920705,
      "grad_norm": 1.1294559240341187,
      "learning_rate": 1.5466960352422908e-05,
      "loss": 0.1077,
      "step": 1030
    },
    {
      "epoch": 4.581497797356828,
      "grad_norm": 1.2807523012161255,
      "learning_rate": 1.5422907488986784e-05,
      "loss": 0.1145,
      "step": 1040
    },
    {
      "epoch": 4.6255506607929515,
      "grad_norm": 1.2320072650909424,
      "learning_rate": 1.537885462555066e-05,
      "loss": 0.106,
      "step": 1050
    },
    {
      "epoch": 4.669603524229075,
      "grad_norm": 1.4052196741104126,
      "learning_rate": 1.533480176211454e-05,
      "loss": 0.1045,
      "step": 1060
    },
    {
      "epoch": 4.713656387665198,
      "grad_norm": 1.1475516557693481,
      "learning_rate": 1.5290748898678417e-05,
      "loss": 0.1071,
      "step": 1070
    },
    {
      "epoch": 4.757709251101321,
      "grad_norm": 1.3057286739349365,
      "learning_rate": 1.5246696035242291e-05,
      "loss": 0.1121,
      "step": 1080
    },
    {
      "epoch": 4.8017621145374445,
      "grad_norm": 1.234433889389038,
      "learning_rate": 1.5202643171806168e-05,
      "loss": 0.1043,
      "step": 1090
    },
    {
      "epoch": 4.845814977973569,
      "grad_norm": 1.7023227214813232,
      "learning_rate": 1.5158590308370044e-05,
      "loss": 0.1106,
      "step": 1100
    },
    {
      "epoch": 4.889867841409692,
      "grad_norm": 1.350649118423462,
      "learning_rate": 1.511453744493392e-05,
      "loss": 0.1085,
      "step": 1110
    },
    {
      "epoch": 4.933920704845815,
      "grad_norm": 1.0196435451507568,
      "learning_rate": 1.50704845814978e-05,
      "loss": 0.1039,
      "step": 1120
    },
    {
      "epoch": 4.977973568281938,
      "grad_norm": 1.189318060874939,
      "learning_rate": 1.5026431718061677e-05,
      "loss": 0.1064,
      "step": 1130
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.10414016246795654,
      "eval_runtime": 27.8652,
      "eval_samples_per_second": 7.249,
      "eval_steps_per_second": 0.933,
      "step": 1135
    },
    {
      "epoch": 5.022026431718062,
      "grad_norm": 1.141148567199707,
      "learning_rate": 1.4982378854625553e-05,
      "loss": 0.1148,
      "step": 1140
    },
    {
      "epoch": 5.066079295154185,
      "grad_norm": 1.3913923501968384,
      "learning_rate": 1.493832599118943e-05,
      "loss": 0.1095,
      "step": 1150
    },
    {
      "epoch": 5.110132158590308,
      "grad_norm": 1.188190221786499,
      "learning_rate": 1.4894273127753304e-05,
      "loss": 0.103,
      "step": 1160
    },
    {
      "epoch": 5.154185022026431,
      "grad_norm": 1.0786947011947632,
      "learning_rate": 1.485022026431718e-05,
      "loss": 0.1016,
      "step": 1170
    },
    {
      "epoch": 5.1982378854625555,
      "grad_norm": 1.2468222379684448,
      "learning_rate": 1.4806167400881057e-05,
      "loss": 0.1054,
      "step": 1180
    },
    {
      "epoch": 5.242290748898679,
      "grad_norm": 1.0989887714385986,
      "learning_rate": 1.4762114537444936e-05,
      "loss": 0.1058,
      "step": 1190
    },
    {
      "epoch": 5.286343612334802,
      "grad_norm": 1.0812631845474243,
      "learning_rate": 1.4718061674008813e-05,
      "loss": 0.1086,
      "step": 1200
    },
    {
      "epoch": 5.330396475770925,
      "grad_norm": 1.1153804063796997,
      "learning_rate": 1.4674008810572689e-05,
      "loss": 0.1021,
      "step": 1210
    },
    {
      "epoch": 5.3744493392070485,
      "grad_norm": 1.1201153993606567,
      "learning_rate": 1.4629955947136566e-05,
      "loss": 0.1113,
      "step": 1220
    },
    {
      "epoch": 5.418502202643172,
      "grad_norm": 1.1307753324508667,
      "learning_rate": 1.4585903083700442e-05,
      "loss": 0.1049,
      "step": 1230
    },
    {
      "epoch": 5.462555066079295,
      "grad_norm": 1.233945608139038,
      "learning_rate": 1.4541850220264318e-05,
      "loss": 0.1104,
      "step": 1240
    },
    {
      "epoch": 5.506607929515418,
      "grad_norm": 1.3647692203521729,
      "learning_rate": 1.4497797356828196e-05,
      "loss": 0.1074,
      "step": 1250
    },
    {
      "epoch": 5.5506607929515415,
      "grad_norm": 1.2439547777175903,
      "learning_rate": 1.4453744493392073e-05,
      "loss": 0.1049,
      "step": 1260
    },
    {
      "epoch": 5.594713656387665,
      "grad_norm": 1.0927038192749023,
      "learning_rate": 1.4409691629955949e-05,
      "loss": 0.1031,
      "step": 1270
    },
    {
      "epoch": 5.638766519823789,
      "grad_norm": 1.1971232891082764,
      "learning_rate": 1.4365638766519825e-05,
      "loss": 0.1002,
      "step": 1280
    },
    {
      "epoch": 5.682819383259912,
      "grad_norm": 0.9924586415290833,
      "learning_rate": 1.4321585903083702e-05,
      "loss": 0.1104,
      "step": 1290
    },
    {
      "epoch": 5.726872246696035,
      "grad_norm": 0.9370975494384766,
      "learning_rate": 1.4277533039647578e-05,
      "loss": 0.1032,
      "step": 1300
    },
    {
      "epoch": 5.770925110132159,
      "grad_norm": 1.014693260192871,
      "learning_rate": 1.4233480176211454e-05,
      "loss": 0.1129,
      "step": 1310
    },
    {
      "epoch": 5.814977973568282,
      "grad_norm": 1.2448722124099731,
      "learning_rate": 1.4189427312775332e-05,
      "loss": 0.1003,
      "step": 1320
    },
    {
      "epoch": 5.859030837004405,
      "grad_norm": 1.0981937646865845,
      "learning_rate": 1.4145374449339209e-05,
      "loss": 0.111,
      "step": 1330
    },
    {
      "epoch": 5.903083700440528,
      "grad_norm": 1.1587177515029907,
      "learning_rate": 1.4101321585903085e-05,
      "loss": 0.1035,
      "step": 1340
    },
    {
      "epoch": 5.9471365638766525,
      "grad_norm": 0.990730345249176,
      "learning_rate": 1.4057268722466962e-05,
      "loss": 0.0992,
      "step": 1350
    },
    {
      "epoch": 5.991189427312776,
      "grad_norm": 1.3010319471359253,
      "learning_rate": 1.4013215859030838e-05,
      "loss": 0.1069,
      "step": 1360
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.10176602751016617,
      "eval_runtime": 27.8104,
      "eval_samples_per_second": 7.263,
      "eval_steps_per_second": 0.935,
      "step": 1362
    },
    {
      "epoch": 6.035242290748899,
      "grad_norm": 1.259992241859436,
      "learning_rate": 1.3969162995594714e-05,
      "loss": 0.1024,
      "step": 1370
    },
    {
      "epoch": 6.079295154185022,
      "grad_norm": 1.1231591701507568,
      "learning_rate": 1.3925110132158592e-05,
      "loss": 0.1024,
      "step": 1380
    },
    {
      "epoch": 6.1233480176211454,
      "grad_norm": 0.9895966053009033,
      "learning_rate": 1.3881057268722469e-05,
      "loss": 0.0993,
      "step": 1390
    },
    {
      "epoch": 6.167400881057269,
      "grad_norm": 1.0455162525177002,
      "learning_rate": 1.3837004405286345e-05,
      "loss": 0.1028,
      "step": 1400
    },
    {
      "epoch": 6.211453744493392,
      "grad_norm": 1.2585963010787964,
      "learning_rate": 1.3792951541850221e-05,
      "loss": 0.1082,
      "step": 1410
    },
    {
      "epoch": 6.255506607929515,
      "grad_norm": 1.1978567838668823,
      "learning_rate": 1.3748898678414098e-05,
      "loss": 0.1021,
      "step": 1420
    },
    {
      "epoch": 6.299559471365638,
      "grad_norm": 1.2901077270507812,
      "learning_rate": 1.3704845814977974e-05,
      "loss": 0.0989,
      "step": 1430
    },
    {
      "epoch": 6.343612334801762,
      "grad_norm": 1.0098419189453125,
      "learning_rate": 1.366079295154185e-05,
      "loss": 0.105,
      "step": 1440
    },
    {
      "epoch": 6.387665198237886,
      "grad_norm": 1.0856553316116333,
      "learning_rate": 1.3616740088105729e-05,
      "loss": 0.0974,
      "step": 1450
    },
    {
      "epoch": 6.431718061674009,
      "grad_norm": 1.0914103984832764,
      "learning_rate": 1.3572687224669605e-05,
      "loss": 0.1039,
      "step": 1460
    },
    {
      "epoch": 6.475770925110132,
      "grad_norm": 1.2580724954605103,
      "learning_rate": 1.3528634361233481e-05,
      "loss": 0.1136,
      "step": 1470
    },
    {
      "epoch": 6.5198237885462555,
      "grad_norm": 1.0056192874908447,
      "learning_rate": 1.3484581497797358e-05,
      "loss": 0.0992,
      "step": 1480
    },
    {
      "epoch": 6.563876651982379,
      "grad_norm": 1.0970127582550049,
      "learning_rate": 1.3440528634361234e-05,
      "loss": 0.1044,
      "step": 1490
    },
    {
      "epoch": 6.607929515418502,
      "grad_norm": 0.9838333129882812,
      "learning_rate": 1.339647577092511e-05,
      "loss": 0.1054,
      "step": 1500
    },
    {
      "epoch": 6.651982378854625,
      "grad_norm": 1.2562003135681152,
      "learning_rate": 1.3352422907488988e-05,
      "loss": 0.1003,
      "step": 1510
    },
    {
      "epoch": 6.6960352422907485,
      "grad_norm": 0.923453688621521,
      "learning_rate": 1.3308370044052865e-05,
      "loss": 0.1023,
      "step": 1520
    },
    {
      "epoch": 6.740088105726873,
      "grad_norm": 1.1262893676757812,
      "learning_rate": 1.3264317180616741e-05,
      "loss": 0.1054,
      "step": 1530
    },
    {
      "epoch": 6.784140969162996,
      "grad_norm": 1.2860418558120728,
      "learning_rate": 1.3220264317180617e-05,
      "loss": 0.1052,
      "step": 1540
    },
    {
      "epoch": 6.828193832599119,
      "grad_norm": 1.2016862630844116,
      "learning_rate": 1.3176211453744494e-05,
      "loss": 0.1034,
      "step": 1550
    },
    {
      "epoch": 6.872246696035242,
      "grad_norm": 1.0928360223770142,
      "learning_rate": 1.313215859030837e-05,
      "loss": 0.1055,
      "step": 1560
    },
    {
      "epoch": 6.916299559471366,
      "grad_norm": 1.0457162857055664,
      "learning_rate": 1.3088105726872246e-05,
      "loss": 0.1009,
      "step": 1570
    },
    {
      "epoch": 6.960352422907489,
      "grad_norm": 0.988227903842926,
      "learning_rate": 1.3044052863436125e-05,
      "loss": 0.1005,
      "step": 1580
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.09978660941123962,
      "eval_runtime": 27.8538,
      "eval_samples_per_second": 7.252,
      "eval_steps_per_second": 0.933,
      "step": 1589
    },
    {
      "epoch": 7.004405286343612,
      "grad_norm": 1.1988884210586548,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.1021,
      "step": 1590
    },
    {
      "epoch": 7.048458149779735,
      "grad_norm": 1.0164753198623657,
      "learning_rate": 1.2955947136563877e-05,
      "loss": 0.0993,
      "step": 1600
    },
    {
      "epoch": 7.092511013215859,
      "grad_norm": 1.0064870119094849,
      "learning_rate": 1.2911894273127754e-05,
      "loss": 0.1016,
      "step": 1610
    },
    {
      "epoch": 7.136563876651983,
      "grad_norm": 1.0699419975280762,
      "learning_rate": 1.286784140969163e-05,
      "loss": 0.1081,
      "step": 1620
    },
    {
      "epoch": 7.180616740088106,
      "grad_norm": 1.2877646684646606,
      "learning_rate": 1.2823788546255506e-05,
      "loss": 0.1028,
      "step": 1630
    },
    {
      "epoch": 7.224669603524229,
      "grad_norm": 1.0146914720535278,
      "learning_rate": 1.2779735682819386e-05,
      "loss": 0.0998,
      "step": 1640
    },
    {
      "epoch": 7.2687224669603525,
      "grad_norm": 1.131920337677002,
      "learning_rate": 1.273568281938326e-05,
      "loss": 0.101,
      "step": 1650
    },
    {
      "epoch": 7.312775330396476,
      "grad_norm": 1.0530768632888794,
      "learning_rate": 1.2691629955947137e-05,
      "loss": 0.099,
      "step": 1660
    },
    {
      "epoch": 7.356828193832599,
      "grad_norm": 1.0987300872802734,
      "learning_rate": 1.2647577092511013e-05,
      "loss": 0.1032,
      "step": 1670
    },
    {
      "epoch": 7.400881057268722,
      "grad_norm": 1.0725817680358887,
      "learning_rate": 1.260352422907489e-05,
      "loss": 0.0973,
      "step": 1680
    },
    {
      "epoch": 7.4449339207048455,
      "grad_norm": 0.9859964847564697,
      "learning_rate": 1.2559471365638766e-05,
      "loss": 0.1006,
      "step": 1690
    },
    {
      "epoch": 7.48898678414097,
      "grad_norm": 1.1333906650543213,
      "learning_rate": 1.2515418502202643e-05,
      "loss": 0.101,
      "step": 1700
    },
    {
      "epoch": 7.533039647577093,
      "grad_norm": 0.9303945302963257,
      "learning_rate": 1.2471365638766522e-05,
      "loss": 0.096,
      "step": 1710
    },
    {
      "epoch": 7.577092511013216,
      "grad_norm": 0.9656496047973633,
      "learning_rate": 1.2427312775330399e-05,
      "loss": 0.0991,
      "step": 1720
    },
    {
      "epoch": 7.621145374449339,
      "grad_norm": 1.0780339241027832,
      "learning_rate": 1.2383259911894275e-05,
      "loss": 0.1015,
      "step": 1730
    },
    {
      "epoch": 7.665198237885463,
      "grad_norm": 1.0240912437438965,
      "learning_rate": 1.2339207048458151e-05,
      "loss": 0.098,
      "step": 1740
    },
    {
      "epoch": 7.709251101321586,
      "grad_norm": 1.1222833395004272,
      "learning_rate": 1.2295154185022026e-05,
      "loss": 0.1007,
      "step": 1750
    },
    {
      "epoch": 7.753303964757709,
      "grad_norm": 1.1088637113571167,
      "learning_rate": 1.2251101321585902e-05,
      "loss": 0.1051,
      "step": 1760
    },
    {
      "epoch": 7.797356828193832,
      "grad_norm": 0.9728372097015381,
      "learning_rate": 1.2207048458149782e-05,
      "loss": 0.0982,
      "step": 1770
    },
    {
      "epoch": 7.841409691629956,
      "grad_norm": 1.1152907609939575,
      "learning_rate": 1.2162995594713658e-05,
      "loss": 0.1006,
      "step": 1780
    },
    {
      "epoch": 7.885462555066079,
      "grad_norm": 1.315031886100769,
      "learning_rate": 1.2118942731277535e-05,
      "loss": 0.1029,
      "step": 1790
    },
    {
      "epoch": 7.929515418502203,
      "grad_norm": 1.0810997486114502,
      "learning_rate": 1.2074889867841411e-05,
      "loss": 0.1007,
      "step": 1800
    },
    {
      "epoch": 7.973568281938326,
      "grad_norm": 1.0791438817977905,
      "learning_rate": 1.2030837004405288e-05,
      "loss": 0.102,
      "step": 1810
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.09817685931921005,
      "eval_runtime": 28.0146,
      "eval_samples_per_second": 7.211,
      "eval_steps_per_second": 0.928,
      "step": 1816
    },
    {
      "epoch": 8.017621145374449,
      "grad_norm": 1.134476900100708,
      "learning_rate": 1.1986784140969164e-05,
      "loss": 0.098,
      "step": 1820
    },
    {
      "epoch": 8.061674008810572,
      "grad_norm": 0.8918788433074951,
      "learning_rate": 1.1942731277533042e-05,
      "loss": 0.0997,
      "step": 1830
    },
    {
      "epoch": 8.105726872246697,
      "grad_norm": 1.0399987697601318,
      "learning_rate": 1.1898678414096918e-05,
      "loss": 0.0966,
      "step": 1840
    },
    {
      "epoch": 8.14977973568282,
      "grad_norm": 1.0496113300323486,
      "learning_rate": 1.1854625550660795e-05,
      "loss": 0.1024,
      "step": 1850
    },
    {
      "epoch": 8.193832599118943,
      "grad_norm": 0.9915745854377747,
      "learning_rate": 1.1810572687224671e-05,
      "loss": 0.1031,
      "step": 1860
    },
    {
      "epoch": 8.237885462555067,
      "grad_norm": 1.1005696058273315,
      "learning_rate": 1.1766519823788547e-05,
      "loss": 0.1073,
      "step": 1870
    },
    {
      "epoch": 8.28193832599119,
      "grad_norm": 1.1825687885284424,
      "learning_rate": 1.1722466960352424e-05,
      "loss": 0.0956,
      "step": 1880
    },
    {
      "epoch": 8.325991189427313,
      "grad_norm": 1.0802628993988037,
      "learning_rate": 1.16784140969163e-05,
      "loss": 0.0997,
      "step": 1890
    },
    {
      "epoch": 8.370044052863436,
      "grad_norm": 1.2125627994537354,
      "learning_rate": 1.1634361233480178e-05,
      "loss": 0.0953,
      "step": 1900
    },
    {
      "epoch": 8.41409691629956,
      "grad_norm": 1.0930864810943604,
      "learning_rate": 1.1590308370044054e-05,
      "loss": 0.1011,
      "step": 1910
    },
    {
      "epoch": 8.458149779735683,
      "grad_norm": 0.9460774660110474,
      "learning_rate": 1.1546255506607931e-05,
      "loss": 0.0961,
      "step": 1920
    },
    {
      "epoch": 8.502202643171806,
      "grad_norm": 1.3361636400222778,
      "learning_rate": 1.1502202643171807e-05,
      "loss": 0.099,
      "step": 1930
    },
    {
      "epoch": 8.54625550660793,
      "grad_norm": 1.0078848600387573,
      "learning_rate": 1.1458149779735684e-05,
      "loss": 0.1008,
      "step": 1940
    },
    {
      "epoch": 8.590308370044053,
      "grad_norm": 0.9466846585273743,
      "learning_rate": 1.141409691629956e-05,
      "loss": 0.0967,
      "step": 1950
    },
    {
      "epoch": 8.634361233480176,
      "grad_norm": 1.250486135482788,
      "learning_rate": 1.1370044052863438e-05,
      "loss": 0.0987,
      "step": 1960
    },
    {
      "epoch": 8.678414096916299,
      "grad_norm": 1.1625604629516602,
      "learning_rate": 1.1325991189427314e-05,
      "loss": 0.0977,
      "step": 1970
    },
    {
      "epoch": 8.722466960352422,
      "grad_norm": 0.8342958688735962,
      "learning_rate": 1.128193832599119e-05,
      "loss": 0.1005,
      "step": 1980
    },
    {
      "epoch": 8.766519823788546,
      "grad_norm": 1.0759474039077759,
      "learning_rate": 1.1237885462555067e-05,
      "loss": 0.0998,
      "step": 1990
    },
    {
      "epoch": 8.810572687224669,
      "grad_norm": 1.1449650526046753,
      "learning_rate": 1.1193832599118943e-05,
      "loss": 0.0967,
      "step": 2000
    },
    {
      "epoch": 8.854625550660792,
      "grad_norm": 1.1507503986358643,
      "learning_rate": 1.114977973568282e-05,
      "loss": 0.098,
      "step": 2010
    },
    {
      "epoch": 8.898678414096917,
      "grad_norm": 1.0004643201828003,
      "learning_rate": 1.1105726872246696e-05,
      "loss": 0.1009,
      "step": 2020
    },
    {
      "epoch": 8.94273127753304,
      "grad_norm": 1.0951207876205444,
      "learning_rate": 1.1061674008810574e-05,
      "loss": 0.0988,
      "step": 2030
    },
    {
      "epoch": 8.986784140969164,
      "grad_norm": 0.9956575036048889,
      "learning_rate": 1.101762114537445e-05,
      "loss": 0.0973,
      "step": 2040
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.09665348380804062,
      "eval_runtime": 27.8911,
      "eval_samples_per_second": 7.242,
      "eval_steps_per_second": 0.932,
      "step": 2043
    },
    {
      "epoch": 9.030837004405287,
      "grad_norm": 1.306032419204712,
      "learning_rate": 1.0973568281938327e-05,
      "loss": 0.1045,
      "step": 2050
    },
    {
      "epoch": 9.07488986784141,
      "grad_norm": 1.0859533548355103,
      "learning_rate": 1.0929515418502203e-05,
      "loss": 0.1052,
      "step": 2060
    },
    {
      "epoch": 9.118942731277533,
      "grad_norm": 0.9349321722984314,
      "learning_rate": 1.088546255506608e-05,
      "loss": 0.0992,
      "step": 2070
    },
    {
      "epoch": 9.162995594713657,
      "grad_norm": 1.108841061592102,
      "learning_rate": 1.0841409691629956e-05,
      "loss": 0.0929,
      "step": 2080
    },
    {
      "epoch": 9.20704845814978,
      "grad_norm": 1.253301978111267,
      "learning_rate": 1.0797356828193834e-05,
      "loss": 0.0927,
      "step": 2090
    },
    {
      "epoch": 9.251101321585903,
      "grad_norm": 1.0414780378341675,
      "learning_rate": 1.075330396475771e-05,
      "loss": 0.0993,
      "step": 2100
    },
    {
      "epoch": 9.295154185022026,
      "grad_norm": 1.0898252725601196,
      "learning_rate": 1.0709251101321587e-05,
      "loss": 0.0978,
      "step": 2110
    },
    {
      "epoch": 9.33920704845815,
      "grad_norm": 1.124242901802063,
      "learning_rate": 1.0665198237885463e-05,
      "loss": 0.0978,
      "step": 2120
    },
    {
      "epoch": 9.383259911894273,
      "grad_norm": 1.0448578596115112,
      "learning_rate": 1.062114537444934e-05,
      "loss": 0.0995,
      "step": 2130
    },
    {
      "epoch": 9.427312775330396,
      "grad_norm": 0.8874822854995728,
      "learning_rate": 1.0577092511013216e-05,
      "loss": 0.1,
      "step": 2140
    },
    {
      "epoch": 9.47136563876652,
      "grad_norm": 1.056687831878662,
      "learning_rate": 1.0533039647577092e-05,
      "loss": 0.0971,
      "step": 2150
    },
    {
      "epoch": 9.515418502202643,
      "grad_norm": 0.9483856558799744,
      "learning_rate": 1.048898678414097e-05,
      "loss": 0.0984,
      "step": 2160
    },
    {
      "epoch": 9.559471365638766,
      "grad_norm": 1.0507066249847412,
      "learning_rate": 1.0444933920704847e-05,
      "loss": 0.097,
      "step": 2170
    },
    {
      "epoch": 9.603524229074889,
      "grad_norm": 1.1334236860275269,
      "learning_rate": 1.0400881057268723e-05,
      "loss": 0.0971,
      "step": 2180
    },
    {
      "epoch": 9.647577092511014,
      "grad_norm": 1.0385996103286743,
      "learning_rate": 1.03568281938326e-05,
      "loss": 0.0985,
      "step": 2190
    },
    {
      "epoch": 9.691629955947137,
      "grad_norm": 1.077332615852356,
      "learning_rate": 1.0312775330396476e-05,
      "loss": 0.0933,
      "step": 2200
    },
    {
      "epoch": 9.73568281938326,
      "grad_norm": 1.0133168697357178,
      "learning_rate": 1.0268722466960352e-05,
      "loss": 0.0946,
      "step": 2210
    },
    {
      "epoch": 9.779735682819384,
      "grad_norm": 1.0571198463439941,
      "learning_rate": 1.0224669603524232e-05,
      "loss": 0.1014,
      "step": 2220
    },
    {
      "epoch": 9.823788546255507,
      "grad_norm": 0.9868198037147522,
      "learning_rate": 1.0180616740088108e-05,
      "loss": 0.0902,
      "step": 2230
    },
    {
      "epoch": 9.86784140969163,
      "grad_norm": 1.0696673393249512,
      "learning_rate": 1.0136563876651984e-05,
      "loss": 0.0978,
      "step": 2240
    },
    {
      "epoch": 9.911894273127754,
      "grad_norm": 1.050253987312317,
      "learning_rate": 1.0092511013215859e-05,
      "loss": 0.0955,
      "step": 2250
    },
    {
      "epoch": 9.955947136563877,
      "grad_norm": 1.0666272640228271,
      "learning_rate": 1.0048458149779735e-05,
      "loss": 0.091,
      "step": 2260
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.0211491584777832,
      "learning_rate": 1.0004405286343612e-05,
      "loss": 0.0943,
      "step": 2270
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.09524963051080704,
      "eval_runtime": 27.8693,
      "eval_samples_per_second": 7.248,
      "eval_steps_per_second": 0.933,
      "step": 2270
    },
    {
      "epoch": 10.044052863436123,
      "grad_norm": 1.1664369106292725,
      "learning_rate": 9.96035242290749e-06,
      "loss": 0.0994,
      "step": 2280
    },
    {
      "epoch": 10.088105726872246,
      "grad_norm": 0.8971592783927917,
      "learning_rate": 9.916299559471366e-06,
      "loss": 0.0981,
      "step": 2290
    },
    {
      "epoch": 10.13215859030837,
      "grad_norm": 1.0257583856582642,
      "learning_rate": 9.872246696035243e-06,
      "loss": 0.0983,
      "step": 2300
    },
    {
      "epoch": 10.176211453744493,
      "grad_norm": 1.1188338994979858,
      "learning_rate": 9.82819383259912e-06,
      "loss": 0.0945,
      "step": 2310
    },
    {
      "epoch": 10.220264317180616,
      "grad_norm": 0.9573460221290588,
      "learning_rate": 9.784140969162997e-06,
      "loss": 0.0915,
      "step": 2320
    },
    {
      "epoch": 10.26431718061674,
      "grad_norm": 0.9567863941192627,
      "learning_rate": 9.740088105726873e-06,
      "loss": 0.0924,
      "step": 2330
    },
    {
      "epoch": 10.308370044052863,
      "grad_norm": 1.0859767198562622,
      "learning_rate": 9.69603524229075e-06,
      "loss": 0.1009,
      "step": 2340
    },
    {
      "epoch": 10.352422907488986,
      "grad_norm": 1.0992237329483032,
      "learning_rate": 9.651982378854626e-06,
      "loss": 0.0981,
      "step": 2350
    },
    {
      "epoch": 10.396475770925111,
      "grad_norm": 1.0613563060760498,
      "learning_rate": 9.607929515418502e-06,
      "loss": 0.0955,
      "step": 2360
    },
    {
      "epoch": 10.440528634361234,
      "grad_norm": 1.0043691396713257,
      "learning_rate": 9.56387665198238e-06,
      "loss": 0.0912,
      "step": 2370
    },
    {
      "epoch": 10.484581497797357,
      "grad_norm": 0.9236245155334473,
      "learning_rate": 9.519823788546257e-06,
      "loss": 0.0999,
      "step": 2380
    },
    {
      "epoch": 10.52863436123348,
      "grad_norm": 1.1522282361984253,
      "learning_rate": 9.475770925110133e-06,
      "loss": 0.0918,
      "step": 2390
    },
    {
      "epoch": 10.572687224669604,
      "grad_norm": 1.0809639692306519,
      "learning_rate": 9.43171806167401e-06,
      "loss": 0.092,
      "step": 2400
    },
    {
      "epoch": 10.616740088105727,
      "grad_norm": 1.1468030214309692,
      "learning_rate": 9.387665198237886e-06,
      "loss": 0.0941,
      "step": 2410
    },
    {
      "epoch": 10.66079295154185,
      "grad_norm": 0.9994056820869446,
      "learning_rate": 9.343612334801762e-06,
      "loss": 0.0982,
      "step": 2420
    },
    {
      "epoch": 10.704845814977974,
      "grad_norm": 0.9094553589820862,
      "learning_rate": 9.29955947136564e-06,
      "loss": 0.097,
      "step": 2430
    },
    {
      "epoch": 10.748898678414097,
      "grad_norm": 1.277694582939148,
      "learning_rate": 9.255506607929517e-06,
      "loss": 0.0984,
      "step": 2440
    },
    {
      "epoch": 10.79295154185022,
      "grad_norm": 1.1888703107833862,
      "learning_rate": 9.211453744493393e-06,
      "loss": 0.1024,
      "step": 2450
    },
    {
      "epoch": 10.837004405286343,
      "grad_norm": 1.084741473197937,
      "learning_rate": 9.16740088105727e-06,
      "loss": 0.0925,
      "step": 2460
    },
    {
      "epoch": 10.881057268722467,
      "grad_norm": 1.0612785816192627,
      "learning_rate": 9.123348017621146e-06,
      "loss": 0.0907,
      "step": 2470
    },
    {
      "epoch": 10.92511013215859,
      "grad_norm": 1.0210204124450684,
      "learning_rate": 9.079295154185022e-06,
      "loss": 0.0962,
      "step": 2480
    },
    {
      "epoch": 10.969162995594713,
      "grad_norm": 0.911893367767334,
      "learning_rate": 9.035242290748898e-06,
      "loss": 0.0883,
      "step": 2490
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.09352649748325348,
      "eval_runtime": 27.9124,
      "eval_samples_per_second": 7.237,
      "eval_steps_per_second": 0.931,
      "step": 2497
    },
    {
      "epoch": 11.013215859030836,
      "grad_norm": 0.9590564370155334,
      "learning_rate": 8.991189427312777e-06,
      "loss": 0.0946,
      "step": 2500
    },
    {
      "epoch": 11.05726872246696,
      "grad_norm": 1.0454305410385132,
      "learning_rate": 8.947136563876653e-06,
      "loss": 0.098,
      "step": 2510
    },
    {
      "epoch": 11.101321585903083,
      "grad_norm": 1.200825572013855,
      "learning_rate": 8.90308370044053e-06,
      "loss": 0.0901,
      "step": 2520
    },
    {
      "epoch": 11.145374449339206,
      "grad_norm": 1.123608946800232,
      "learning_rate": 8.859030837004407e-06,
      "loss": 0.0894,
      "step": 2530
    },
    {
      "epoch": 11.189427312775331,
      "grad_norm": 1.0231136083602905,
      "learning_rate": 8.814977973568282e-06,
      "loss": 0.0881,
      "step": 2540
    },
    {
      "epoch": 11.233480176211454,
      "grad_norm": 1.1613829135894775,
      "learning_rate": 8.770925110132158e-06,
      "loss": 0.1008,
      "step": 2550
    },
    {
      "epoch": 11.277533039647578,
      "grad_norm": 1.0357129573822021,
      "learning_rate": 8.726872246696036e-06,
      "loss": 0.0897,
      "step": 2560
    },
    {
      "epoch": 11.321585903083701,
      "grad_norm": 1.0952898263931274,
      "learning_rate": 8.682819383259913e-06,
      "loss": 0.093,
      "step": 2570
    },
    {
      "epoch": 11.365638766519824,
      "grad_norm": 1.104056715965271,
      "learning_rate": 8.638766519823789e-06,
      "loss": 0.0973,
      "step": 2580
    },
    {
      "epoch": 11.409691629955947,
      "grad_norm": 1.1651544570922852,
      "learning_rate": 8.594713656387665e-06,
      "loss": 0.0933,
      "step": 2590
    },
    {
      "epoch": 11.45374449339207,
      "grad_norm": 1.0167176723480225,
      "learning_rate": 8.550660792951543e-06,
      "loss": 0.0928,
      "step": 2600
    },
    {
      "epoch": 11.497797356828194,
      "grad_norm": 1.0208582878112793,
      "learning_rate": 8.50660792951542e-06,
      "loss": 0.0993,
      "step": 2610
    },
    {
      "epoch": 11.541850220264317,
      "grad_norm": 0.9327733516693115,
      "learning_rate": 8.462555066079296e-06,
      "loss": 0.0968,
      "step": 2620
    },
    {
      "epoch": 11.58590308370044,
      "grad_norm": 1.0302433967590332,
      "learning_rate": 8.418502202643173e-06,
      "loss": 0.0956,
      "step": 2630
    },
    {
      "epoch": 11.629955947136564,
      "grad_norm": 1.0270283222198486,
      "learning_rate": 8.374449339207049e-06,
      "loss": 0.0918,
      "step": 2640
    },
    {
      "epoch": 11.674008810572687,
      "grad_norm": 1.0501774549484253,
      "learning_rate": 8.330396475770925e-06,
      "loss": 0.0947,
      "step": 2650
    },
    {
      "epoch": 11.71806167400881,
      "grad_norm": 0.895592451095581,
      "learning_rate": 8.286343612334803e-06,
      "loss": 0.0904,
      "step": 2660
    },
    {
      "epoch": 11.762114537444933,
      "grad_norm": 1.0230913162231445,
      "learning_rate": 8.24229074889868e-06,
      "loss": 0.0893,
      "step": 2670
    },
    {
      "epoch": 11.806167400881057,
      "grad_norm": 1.1160666942596436,
      "learning_rate": 8.198237885462556e-06,
      "loss": 0.0969,
      "step": 2680
    },
    {
      "epoch": 11.85022026431718,
      "grad_norm": 0.9466071128845215,
      "learning_rate": 8.154185022026432e-06,
      "loss": 0.095,
      "step": 2690
    },
    {
      "epoch": 11.894273127753303,
      "grad_norm": 1.1229631900787354,
      "learning_rate": 8.110132158590309e-06,
      "loss": 0.0924,
      "step": 2700
    },
    {
      "epoch": 11.938325991189426,
      "grad_norm": 1.0974278450012207,
      "learning_rate": 8.066079295154185e-06,
      "loss": 0.0964,
      "step": 2710
    },
    {
      "epoch": 11.982378854625551,
      "grad_norm": 1.0732225179672241,
      "learning_rate": 8.022026431718061e-06,
      "loss": 0.0947,
      "step": 2720
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.09273229539394379,
      "eval_runtime": 27.9372,
      "eval_samples_per_second": 7.231,
      "eval_steps_per_second": 0.931,
      "step": 2724
    },
    {
      "epoch": 12.026431718061675,
      "grad_norm": 0.9839596748352051,
      "learning_rate": 7.97797356828194e-06,
      "loss": 0.0926,
      "step": 2730
    },
    {
      "epoch": 12.070484581497798,
      "grad_norm": 0.8947497606277466,
      "learning_rate": 7.933920704845816e-06,
      "loss": 0.0977,
      "step": 2740
    },
    {
      "epoch": 12.114537444933921,
      "grad_norm": 0.9729079604148865,
      "learning_rate": 7.889867841409692e-06,
      "loss": 0.0907,
      "step": 2750
    },
    {
      "epoch": 12.158590308370044,
      "grad_norm": 1.0679168701171875,
      "learning_rate": 7.845814977973569e-06,
      "loss": 0.092,
      "step": 2760
    },
    {
      "epoch": 12.202643171806168,
      "grad_norm": 1.035445213317871,
      "learning_rate": 7.801762114537445e-06,
      "loss": 0.0953,
      "step": 2770
    },
    {
      "epoch": 12.246696035242291,
      "grad_norm": 0.8994035720825195,
      "learning_rate": 7.757709251101321e-06,
      "loss": 0.0899,
      "step": 2780
    },
    {
      "epoch": 12.290748898678414,
      "grad_norm": 1.0149272680282593,
      "learning_rate": 7.7136563876652e-06,
      "loss": 0.0946,
      "step": 2790
    },
    {
      "epoch": 12.334801762114537,
      "grad_norm": 0.9442780017852783,
      "learning_rate": 7.669603524229076e-06,
      "loss": 0.0911,
      "step": 2800
    },
    {
      "epoch": 12.37885462555066,
      "grad_norm": 1.1212034225463867,
      "learning_rate": 7.625550660792952e-06,
      "loss": 0.0927,
      "step": 2810
    },
    {
      "epoch": 12.422907488986784,
      "grad_norm": 1.0091898441314697,
      "learning_rate": 7.581497797356829e-06,
      "loss": 0.0875,
      "step": 2820
    },
    {
      "epoch": 12.466960352422907,
      "grad_norm": 0.9390499591827393,
      "learning_rate": 7.537444933920706e-06,
      "loss": 0.093,
      "step": 2830
    },
    {
      "epoch": 12.51101321585903,
      "grad_norm": 1.04579758644104,
      "learning_rate": 7.493392070484582e-06,
      "loss": 0.0924,
      "step": 2840
    },
    {
      "epoch": 12.555066079295154,
      "grad_norm": 1.0800150632858276,
      "learning_rate": 7.449339207048458e-06,
      "loss": 0.0866,
      "step": 2850
    },
    {
      "epoch": 12.599118942731277,
      "grad_norm": 1.0097639560699463,
      "learning_rate": 7.4052863436123355e-06,
      "loss": 0.093,
      "step": 2860
    },
    {
      "epoch": 12.6431718061674,
      "grad_norm": 1.1177891492843628,
      "learning_rate": 7.361233480176212e-06,
      "loss": 0.0918,
      "step": 2870
    },
    {
      "epoch": 12.687224669603523,
      "grad_norm": 0.9807650446891785,
      "learning_rate": 7.317180616740088e-06,
      "loss": 0.0937,
      "step": 2880
    },
    {
      "epoch": 12.731277533039648,
      "grad_norm": 1.1373083591461182,
      "learning_rate": 7.2731277533039655e-06,
      "loss": 0.098,
      "step": 2890
    },
    {
      "epoch": 12.775330396475772,
      "grad_norm": 0.9511897563934326,
      "learning_rate": 7.229074889867842e-06,
      "loss": 0.0928,
      "step": 2900
    },
    {
      "epoch": 12.819383259911895,
      "grad_norm": 1.0106353759765625,
      "learning_rate": 7.185022026431718e-06,
      "loss": 0.0965,
      "step": 2910
    },
    {
      "epoch": 12.863436123348018,
      "grad_norm": 0.9804746508598328,
      "learning_rate": 7.140969162995595e-06,
      "loss": 0.0902,
      "step": 2920
    },
    {
      "epoch": 12.907488986784141,
      "grad_norm": 1.1813026666641235,
      "learning_rate": 7.096916299559472e-06,
      "loss": 0.0967,
      "step": 2930
    },
    {
      "epoch": 12.951541850220265,
      "grad_norm": 0.9683423638343811,
      "learning_rate": 7.052863436123348e-06,
      "loss": 0.0868,
      "step": 2940
    },
    {
      "epoch": 12.995594713656388,
      "grad_norm": 1.122445821762085,
      "learning_rate": 7.008810572687226e-06,
      "loss": 0.0995,
      "step": 2950
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.0919710323214531,
      "eval_runtime": 27.8919,
      "eval_samples_per_second": 7.242,
      "eval_steps_per_second": 0.932,
      "step": 2951
    },
    {
      "epoch": 13.039647577092511,
      "grad_norm": 1.1082499027252197,
      "learning_rate": 6.964757709251102e-06,
      "loss": 0.0916,
      "step": 2960
    },
    {
      "epoch": 13.083700440528634,
      "grad_norm": 1.1295485496520996,
      "learning_rate": 6.920704845814978e-06,
      "loss": 0.0878,
      "step": 2970
    },
    {
      "epoch": 13.127753303964758,
      "grad_norm": 0.9975274205207825,
      "learning_rate": 6.876651982378854e-06,
      "loss": 0.0923,
      "step": 2980
    },
    {
      "epoch": 13.17180616740088,
      "grad_norm": 1.1866164207458496,
      "learning_rate": 6.8325991189427324e-06,
      "loss": 0.0915,
      "step": 2990
    },
    {
      "epoch": 13.215859030837004,
      "grad_norm": 1.0470608472824097,
      "learning_rate": 6.788546255506609e-06,
      "loss": 0.0945,
      "step": 3000
    },
    {
      "epoch": 13.259911894273127,
      "grad_norm": 1.1417206525802612,
      "learning_rate": 6.744493392070484e-06,
      "loss": 0.0877,
      "step": 3010
    },
    {
      "epoch": 13.30396475770925,
      "grad_norm": 1.1428680419921875,
      "learning_rate": 6.700440528634362e-06,
      "loss": 0.0952,
      "step": 3020
    },
    {
      "epoch": 13.348017621145374,
      "grad_norm": 0.9750239849090576,
      "learning_rate": 6.656387665198239e-06,
      "loss": 0.0918,
      "step": 3030
    },
    {
      "epoch": 13.392070484581497,
      "grad_norm": 0.9733618497848511,
      "learning_rate": 6.612334801762115e-06,
      "loss": 0.0888,
      "step": 3040
    },
    {
      "epoch": 13.43612334801762,
      "grad_norm": 1.0064414739608765,
      "learning_rate": 6.568281938325992e-06,
      "loss": 0.0917,
      "step": 3050
    },
    {
      "epoch": 13.480176211453745,
      "grad_norm": 0.9915117621421814,
      "learning_rate": 6.524229074889869e-06,
      "loss": 0.0884,
      "step": 3060
    },
    {
      "epoch": 13.524229074889869,
      "grad_norm": 0.9993746876716614,
      "learning_rate": 6.480176211453745e-06,
      "loss": 0.0893,
      "step": 3070
    },
    {
      "epoch": 13.568281938325992,
      "grad_norm": 1.1426830291748047,
      "learning_rate": 6.436123348017622e-06,
      "loss": 0.0988,
      "step": 3080
    },
    {
      "epoch": 13.612334801762115,
      "grad_norm": 1.03836190700531,
      "learning_rate": 6.3920704845814985e-06,
      "loss": 0.0908,
      "step": 3090
    },
    {
      "epoch": 13.656387665198238,
      "grad_norm": 1.031359314918518,
      "learning_rate": 6.348017621145375e-06,
      "loss": 0.0914,
      "step": 3100
    },
    {
      "epoch": 13.700440528634362,
      "grad_norm": 0.9613944888114929,
      "learning_rate": 6.303964757709251e-06,
      "loss": 0.0967,
      "step": 3110
    },
    {
      "epoch": 13.744493392070485,
      "grad_norm": 0.9744057059288025,
      "learning_rate": 6.2599118942731285e-06,
      "loss": 0.0925,
      "step": 3120
    },
    {
      "epoch": 13.788546255506608,
      "grad_norm": 0.9528787732124329,
      "learning_rate": 6.215859030837005e-06,
      "loss": 0.0954,
      "step": 3130
    },
    {
      "epoch": 13.832599118942731,
      "grad_norm": 0.8792255520820618,
      "learning_rate": 6.171806167400881e-06,
      "loss": 0.091,
      "step": 3140
    },
    {
      "epoch": 13.876651982378855,
      "grad_norm": 0.9728679656982422,
      "learning_rate": 6.127753303964758e-06,
      "loss": 0.0929,
      "step": 3150
    },
    {
      "epoch": 13.920704845814978,
      "grad_norm": 0.938093364238739,
      "learning_rate": 6.083700440528635e-06,
      "loss": 0.093,
      "step": 3160
    },
    {
      "epoch": 13.964757709251101,
      "grad_norm": 1.038848638534546,
      "learning_rate": 6.039647577092511e-06,
      "loss": 0.0918,
      "step": 3170
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.09145920723676682,
      "eval_runtime": 28.0239,
      "eval_samples_per_second": 7.208,
      "eval_steps_per_second": 0.928,
      "step": 3178
    },
    {
      "epoch": 14.008810572687224,
      "grad_norm": 0.9346818327903748,
      "learning_rate": 5.995594713656388e-06,
      "loss": 0.0913,
      "step": 3180
    },
    {
      "epoch": 14.052863436123348,
      "grad_norm": 1.0379457473754883,
      "learning_rate": 5.951541850220265e-06,
      "loss": 0.0899,
      "step": 3190
    },
    {
      "epoch": 14.09691629955947,
      "grad_norm": 1.1098153591156006,
      "learning_rate": 5.907488986784141e-06,
      "loss": 0.0886,
      "step": 3200
    },
    {
      "epoch": 14.140969162995594,
      "grad_norm": 1.0695768594741821,
      "learning_rate": 5.863436123348018e-06,
      "loss": 0.0898,
      "step": 3210
    },
    {
      "epoch": 14.185022026431717,
      "grad_norm": 1.0325738191604614,
      "learning_rate": 5.8193832599118946e-06,
      "loss": 0.0928,
      "step": 3220
    },
    {
      "epoch": 14.229074889867842,
      "grad_norm": 1.4096662998199463,
      "learning_rate": 5.775330396475771e-06,
      "loss": 0.0909,
      "step": 3230
    },
    {
      "epoch": 14.273127753303966,
      "grad_norm": 1.0637110471725464,
      "learning_rate": 5.731277533039647e-06,
      "loss": 0.0937,
      "step": 3240
    },
    {
      "epoch": 14.317180616740089,
      "grad_norm": 0.9748002886772156,
      "learning_rate": 5.687224669603525e-06,
      "loss": 0.0911,
      "step": 3250
    },
    {
      "epoch": 14.361233480176212,
      "grad_norm": 1.0076884031295776,
      "learning_rate": 5.643171806167401e-06,
      "loss": 0.0912,
      "step": 3260
    },
    {
      "epoch": 14.405286343612335,
      "grad_norm": 1.3472537994384766,
      "learning_rate": 5.599118942731277e-06,
      "loss": 0.0943,
      "step": 3270
    },
    {
      "epoch": 14.449339207048459,
      "grad_norm": 1.1010565757751465,
      "learning_rate": 5.555066079295155e-06,
      "loss": 0.0927,
      "step": 3280
    },
    {
      "epoch": 14.493392070484582,
      "grad_norm": 0.9681566953659058,
      "learning_rate": 5.511013215859032e-06,
      "loss": 0.0911,
      "step": 3290
    },
    {
      "epoch": 14.537444933920705,
      "grad_norm": 0.982459306716919,
      "learning_rate": 5.466960352422908e-06,
      "loss": 0.0936,
      "step": 3300
    },
    {
      "epoch": 14.581497797356828,
      "grad_norm": 1.1160575151443481,
      "learning_rate": 5.422907488986785e-06,
      "loss": 0.0856,
      "step": 3310
    },
    {
      "epoch": 14.625550660792952,
      "grad_norm": 1.0608248710632324,
      "learning_rate": 5.3788546255506615e-06,
      "loss": 0.0951,
      "step": 3320
    },
    {
      "epoch": 14.669603524229075,
      "grad_norm": 1.0358628034591675,
      "learning_rate": 5.334801762114538e-06,
      "loss": 0.0863,
      "step": 3330
    },
    {
      "epoch": 14.713656387665198,
      "grad_norm": 1.2733886241912842,
      "learning_rate": 5.290748898678415e-06,
      "loss": 0.0887,
      "step": 3340
    },
    {
      "epoch": 14.757709251101321,
      "grad_norm": 1.0862058401107788,
      "learning_rate": 5.2466960352422915e-06,
      "loss": 0.095,
      "step": 3350
    },
    {
      "epoch": 14.801762114537445,
      "grad_norm": 1.041212797164917,
      "learning_rate": 5.202643171806168e-06,
      "loss": 0.0957,
      "step": 3360
    },
    {
      "epoch": 14.845814977973568,
      "grad_norm": 0.8890644907951355,
      "learning_rate": 5.158590308370044e-06,
      "loss": 0.091,
      "step": 3370
    },
    {
      "epoch": 14.889867841409691,
      "grad_norm": 1.0092953443527222,
      "learning_rate": 5.114537444933921e-06,
      "loss": 0.093,
      "step": 3380
    },
    {
      "epoch": 14.933920704845814,
      "grad_norm": 1.0017346143722534,
      "learning_rate": 5.070484581497798e-06,
      "loss": 0.0884,
      "step": 3390
    },
    {
      "epoch": 14.97797356828194,
      "grad_norm": 1.0474393367767334,
      "learning_rate": 5.026431718061674e-06,
      "loss": 0.0885,
      "step": 3400
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.09101882576942444,
      "eval_runtime": 28.0505,
      "eval_samples_per_second": 7.201,
      "eval_steps_per_second": 0.927,
      "step": 3405
    },
    {
      "epoch": 15.022026431718063,
      "grad_norm": 1.0542985200881958,
      "learning_rate": 4.9823788546255504e-06,
      "loss": 0.102,
      "step": 3410
    },
    {
      "epoch": 15.066079295154186,
      "grad_norm": 1.1155788898468018,
      "learning_rate": 4.938325991189428e-06,
      "loss": 0.0909,
      "step": 3420
    },
    {
      "epoch": 15.110132158590309,
      "grad_norm": 1.0721646547317505,
      "learning_rate": 4.894273127753305e-06,
      "loss": 0.0925,
      "step": 3430
    },
    {
      "epoch": 15.154185022026432,
      "grad_norm": 0.94780033826828,
      "learning_rate": 4.850220264317181e-06,
      "loss": 0.0913,
      "step": 3440
    },
    {
      "epoch": 15.198237885462555,
      "grad_norm": 1.1314537525177002,
      "learning_rate": 4.8061674008810576e-06,
      "loss": 0.0902,
      "step": 3450
    },
    {
      "epoch": 15.242290748898679,
      "grad_norm": 1.1300767660140991,
      "learning_rate": 4.762114537444935e-06,
      "loss": 0.0929,
      "step": 3460
    },
    {
      "epoch": 15.286343612334802,
      "grad_norm": 0.9311705231666565,
      "learning_rate": 4.718061674008811e-06,
      "loss": 0.0896,
      "step": 3470
    },
    {
      "epoch": 15.330396475770925,
      "grad_norm": 1.3068050146102905,
      "learning_rate": 4.6740088105726875e-06,
      "loss": 0.0888,
      "step": 3480
    },
    {
      "epoch": 15.374449339207048,
      "grad_norm": 1.0277605056762695,
      "learning_rate": 4.629955947136564e-06,
      "loss": 0.093,
      "step": 3490
    },
    {
      "epoch": 15.418502202643172,
      "grad_norm": 1.1852281093597412,
      "learning_rate": 4.585903083700441e-06,
      "loss": 0.0902,
      "step": 3500
    },
    {
      "epoch": 15.462555066079295,
      "grad_norm": 1.0512852668762207,
      "learning_rate": 4.541850220264317e-06,
      "loss": 0.0904,
      "step": 3510
    },
    {
      "epoch": 15.506607929515418,
      "grad_norm": 1.0818248987197876,
      "learning_rate": 4.497797356828194e-06,
      "loss": 0.0955,
      "step": 3520
    },
    {
      "epoch": 15.550660792951541,
      "grad_norm": 1.1052632331848145,
      "learning_rate": 4.453744493392071e-06,
      "loss": 0.0854,
      "step": 3530
    },
    {
      "epoch": 15.594713656387665,
      "grad_norm": 1.1069644689559937,
      "learning_rate": 4.409691629955947e-06,
      "loss": 0.0901,
      "step": 3540
    },
    {
      "epoch": 15.638766519823788,
      "grad_norm": 1.1213624477386475,
      "learning_rate": 4.365638766519824e-06,
      "loss": 0.0874,
      "step": 3550
    },
    {
      "epoch": 15.682819383259911,
      "grad_norm": 1.040543556213379,
      "learning_rate": 4.321585903083701e-06,
      "loss": 0.092,
      "step": 3560
    },
    {
      "epoch": 15.726872246696034,
      "grad_norm": 1.0581920146942139,
      "learning_rate": 4.277533039647577e-06,
      "loss": 0.0952,
      "step": 3570
    },
    {
      "epoch": 15.770925110132158,
      "grad_norm": 1.1345022916793823,
      "learning_rate": 4.2334801762114544e-06,
      "loss": 0.0887,
      "step": 3580
    },
    {
      "epoch": 15.814977973568283,
      "grad_norm": 1.0341696739196777,
      "learning_rate": 4.189427312775331e-06,
      "loss": 0.0867,
      "step": 3590
    },
    {
      "epoch": 15.859030837004406,
      "grad_norm": 1.0976999998092651,
      "learning_rate": 4.145374449339207e-06,
      "loss": 0.0924,
      "step": 3600
    },
    {
      "epoch": 15.90308370044053,
      "grad_norm": 1.1510974168777466,
      "learning_rate": 4.101321585903084e-06,
      "loss": 0.0924,
      "step": 3610
    },
    {
      "epoch": 15.947136563876652,
      "grad_norm": 1.1185591220855713,
      "learning_rate": 4.057268722466961e-06,
      "loss": 0.0892,
      "step": 3620
    },
    {
      "epoch": 15.991189427312776,
      "grad_norm": 1.0575107336044312,
      "learning_rate": 4.013215859030837e-06,
      "loss": 0.0884,
      "step": 3630
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.0909196063876152,
      "eval_runtime": 28.052,
      "eval_samples_per_second": 7.201,
      "eval_steps_per_second": 0.927,
      "step": 3632
    },
    {
      "epoch": 16.035242290748897,
      "grad_norm": 0.9971521496772766,
      "learning_rate": 3.969162995594714e-06,
      "loss": 0.0871,
      "step": 3640
    },
    {
      "epoch": 16.079295154185022,
      "grad_norm": 1.135663390159607,
      "learning_rate": 3.925110132158591e-06,
      "loss": 0.0864,
      "step": 3650
    },
    {
      "epoch": 16.123348017621144,
      "grad_norm": 1.063253402709961,
      "learning_rate": 3.881057268722467e-06,
      "loss": 0.0951,
      "step": 3660
    },
    {
      "epoch": 16.16740088105727,
      "grad_norm": 1.0022156238555908,
      "learning_rate": 3.837004405286343e-06,
      "loss": 0.0862,
      "step": 3670
    },
    {
      "epoch": 16.211453744493394,
      "grad_norm": 1.084027886390686,
      "learning_rate": 3.7929515418502206e-06,
      "loss": 0.0874,
      "step": 3680
    },
    {
      "epoch": 16.255506607929515,
      "grad_norm": 1.064104437828064,
      "learning_rate": 3.7488986784140973e-06,
      "loss": 0.0926,
      "step": 3690
    },
    {
      "epoch": 16.29955947136564,
      "grad_norm": 1.08041512966156,
      "learning_rate": 3.7048458149779737e-06,
      "loss": 0.0886,
      "step": 3700
    },
    {
      "epoch": 16.34361233480176,
      "grad_norm": 1.0849270820617676,
      "learning_rate": 3.6607929515418505e-06,
      "loss": 0.0954,
      "step": 3710
    },
    {
      "epoch": 16.387665198237887,
      "grad_norm": 1.1679351329803467,
      "learning_rate": 3.6167400881057273e-06,
      "loss": 0.0887,
      "step": 3720
    },
    {
      "epoch": 16.431718061674008,
      "grad_norm": 1.0208544731140137,
      "learning_rate": 3.5726872246696036e-06,
      "loss": 0.091,
      "step": 3730
    },
    {
      "epoch": 16.475770925110133,
      "grad_norm": 1.1060340404510498,
      "learning_rate": 3.5286343612334804e-06,
      "loss": 0.0919,
      "step": 3740
    },
    {
      "epoch": 16.519823788546255,
      "grad_norm": 1.1005589962005615,
      "learning_rate": 3.4845814977973568e-06,
      "loss": 0.089,
      "step": 3750
    },
    {
      "epoch": 16.56387665198238,
      "grad_norm": 1.0663119554519653,
      "learning_rate": 3.4405286343612335e-06,
      "loss": 0.0949,
      "step": 3760
    },
    {
      "epoch": 16.6079295154185,
      "grad_norm": 1.182358741760254,
      "learning_rate": 3.3964757709251107e-06,
      "loss": 0.0939,
      "step": 3770
    },
    {
      "epoch": 16.651982378854626,
      "grad_norm": 0.9136999845504761,
      "learning_rate": 3.352422907488987e-06,
      "loss": 0.0886,
      "step": 3780
    },
    {
      "epoch": 16.696035242290748,
      "grad_norm": 1.085546851158142,
      "learning_rate": 3.308370044052864e-06,
      "loss": 0.0858,
      "step": 3790
    },
    {
      "epoch": 16.740088105726873,
      "grad_norm": 0.9985621571540833,
      "learning_rate": 3.2643171806167402e-06,
      "loss": 0.0912,
      "step": 3800
    },
    {
      "epoch": 16.784140969162994,
      "grad_norm": 1.0391889810562134,
      "learning_rate": 3.220264317180617e-06,
      "loss": 0.0889,
      "step": 3810
    },
    {
      "epoch": 16.82819383259912,
      "grad_norm": 1.04081130027771,
      "learning_rate": 3.176211453744494e-06,
      "loss": 0.0885,
      "step": 3820
    },
    {
      "epoch": 16.87224669603524,
      "grad_norm": 1.027126669883728,
      "learning_rate": 3.13215859030837e-06,
      "loss": 0.0878,
      "step": 3830
    },
    {
      "epoch": 16.916299559471366,
      "grad_norm": 1.2127619981765747,
      "learning_rate": 3.088105726872247e-06,
      "loss": 0.093,
      "step": 3840
    },
    {
      "epoch": 16.96035242290749,
      "grad_norm": 1.1422971487045288,
      "learning_rate": 3.0440528634361237e-06,
      "loss": 0.0901,
      "step": 3850
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.090370774269104,
      "eval_runtime": 27.8141,
      "eval_samples_per_second": 7.262,
      "eval_steps_per_second": 0.935,
      "step": 3859
    },
    {
      "epoch": 17.004405286343612,
      "grad_norm": 1.0308692455291748,
      "learning_rate": 3e-06,
      "loss": 0.0953,
      "step": 3860
    },
    {
      "epoch": 17.048458149779737,
      "grad_norm": 1.1782512664794922,
      "learning_rate": 2.955947136563877e-06,
      "loss": 0.0971,
      "step": 3870
    },
    {
      "epoch": 17.09251101321586,
      "grad_norm": 1.016487717628479,
      "learning_rate": 2.9118942731277532e-06,
      "loss": 0.0881,
      "step": 3880
    },
    {
      "epoch": 17.136563876651984,
      "grad_norm": 1.0854175090789795,
      "learning_rate": 2.86784140969163e-06,
      "loss": 0.0885,
      "step": 3890
    },
    {
      "epoch": 17.180616740088105,
      "grad_norm": 1.0615530014038086,
      "learning_rate": 2.823788546255507e-06,
      "loss": 0.0897,
      "step": 3900
    },
    {
      "epoch": 17.22466960352423,
      "grad_norm": 1.0412495136260986,
      "learning_rate": 2.779735682819383e-06,
      "loss": 0.0912,
      "step": 3910
    },
    {
      "epoch": 17.26872246696035,
      "grad_norm": 1.1151998043060303,
      "learning_rate": 2.7356828193832603e-06,
      "loss": 0.0889,
      "step": 3920
    },
    {
      "epoch": 17.312775330396477,
      "grad_norm": 1.0220867395401,
      "learning_rate": 2.691629955947137e-06,
      "loss": 0.0901,
      "step": 3930
    },
    {
      "epoch": 17.356828193832598,
      "grad_norm": 1.085695743560791,
      "learning_rate": 2.6475770925110135e-06,
      "loss": 0.0939,
      "step": 3940
    },
    {
      "epoch": 17.400881057268723,
      "grad_norm": 1.2135772705078125,
      "learning_rate": 2.6035242290748903e-06,
      "loss": 0.0899,
      "step": 3950
    },
    {
      "epoch": 17.444933920704845,
      "grad_norm": 1.0706415176391602,
      "learning_rate": 2.5594713656387666e-06,
      "loss": 0.0881,
      "step": 3960
    },
    {
      "epoch": 17.48898678414097,
      "grad_norm": 1.0433716773986816,
      "learning_rate": 2.5154185022026434e-06,
      "loss": 0.0859,
      "step": 3970
    },
    {
      "epoch": 17.53303964757709,
      "grad_norm": 1.0819828510284424,
      "learning_rate": 2.47136563876652e-06,
      "loss": 0.0894,
      "step": 3980
    },
    {
      "epoch": 17.577092511013216,
      "grad_norm": 1.176727533340454,
      "learning_rate": 2.4273127753303965e-06,
      "loss": 0.089,
      "step": 3990
    },
    {
      "epoch": 17.621145374449338,
      "grad_norm": 1.01195228099823,
      "learning_rate": 2.3832599118942733e-06,
      "loss": 0.09,
      "step": 4000
    },
    {
      "epoch": 17.665198237885463,
      "grad_norm": 1.0088937282562256,
      "learning_rate": 2.33920704845815e-06,
      "loss": 0.0891,
      "step": 4010
    },
    {
      "epoch": 17.709251101321584,
      "grad_norm": 1.0086702108383179,
      "learning_rate": 2.2951541850220265e-06,
      "loss": 0.0884,
      "step": 4020
    },
    {
      "epoch": 17.75330396475771,
      "grad_norm": 1.1147189140319824,
      "learning_rate": 2.2511013215859032e-06,
      "loss": 0.0893,
      "step": 4030
    },
    {
      "epoch": 17.797356828193834,
      "grad_norm": 1.1015328168869019,
      "learning_rate": 2.20704845814978e-06,
      "loss": 0.0919,
      "step": 4040
    },
    {
      "epoch": 17.841409691629956,
      "grad_norm": 1.155100703239441,
      "learning_rate": 2.162995594713657e-06,
      "loss": 0.0912,
      "step": 4050
    },
    {
      "epoch": 17.88546255506608,
      "grad_norm": 1.140191674232483,
      "learning_rate": 2.118942731277533e-06,
      "loss": 0.0947,
      "step": 4060
    },
    {
      "epoch": 17.929515418502202,
      "grad_norm": 1.1875988245010376,
      "learning_rate": 2.07488986784141e-06,
      "loss": 0.0878,
      "step": 4070
    },
    {
      "epoch": 17.973568281938327,
      "grad_norm": 1.316331386566162,
      "learning_rate": 2.0308370044052867e-06,
      "loss": 0.0865,
      "step": 4080
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.09034851938486099,
      "eval_runtime": 27.8846,
      "eval_samples_per_second": 7.244,
      "eval_steps_per_second": 0.932,
      "step": 4086
    },
    {
      "epoch": 18.01762114537445,
      "grad_norm": 1.0714298486709595,
      "learning_rate": 1.986784140969163e-06,
      "loss": 0.0858,
      "step": 4090
    },
    {
      "epoch": 18.061674008810574,
      "grad_norm": 1.0001118183135986,
      "learning_rate": 1.94273127753304e-06,
      "loss": 0.0898,
      "step": 4100
    },
    {
      "epoch": 18.105726872246695,
      "grad_norm": 0.9531827569007874,
      "learning_rate": 1.8986784140969164e-06,
      "loss": 0.0909,
      "step": 4110
    },
    {
      "epoch": 18.14977973568282,
      "grad_norm": 1.046545386314392,
      "learning_rate": 1.854625550660793e-06,
      "loss": 0.0893,
      "step": 4120
    },
    {
      "epoch": 18.19383259911894,
      "grad_norm": 1.226488709449768,
      "learning_rate": 1.8105726872246698e-06,
      "loss": 0.0952,
      "step": 4130
    },
    {
      "epoch": 18.237885462555067,
      "grad_norm": 1.0188795328140259,
      "learning_rate": 1.7665198237885463e-06,
      "loss": 0.0961,
      "step": 4140
    },
    {
      "epoch": 18.281938325991188,
      "grad_norm": 1.1388211250305176,
      "learning_rate": 1.722466960352423e-06,
      "loss": 0.0868,
      "step": 4150
    },
    {
      "epoch": 18.325991189427313,
      "grad_norm": 0.9674092531204224,
      "learning_rate": 1.6784140969162997e-06,
      "loss": 0.0905,
      "step": 4160
    },
    {
      "epoch": 18.370044052863435,
      "grad_norm": 1.1233644485473633,
      "learning_rate": 1.6343612334801765e-06,
      "loss": 0.0879,
      "step": 4170
    },
    {
      "epoch": 18.41409691629956,
      "grad_norm": 1.1534072160720825,
      "learning_rate": 1.590308370044053e-06,
      "loss": 0.0843,
      "step": 4180
    },
    {
      "epoch": 18.458149779735685,
      "grad_norm": 1.1760658025741577,
      "learning_rate": 1.5462555066079296e-06,
      "loss": 0.089,
      "step": 4190
    },
    {
      "epoch": 18.502202643171806,
      "grad_norm": 1.0806583166122437,
      "learning_rate": 1.5022026431718062e-06,
      "loss": 0.0905,
      "step": 4200
    },
    {
      "epoch": 18.54625550660793,
      "grad_norm": 0.9249882698059082,
      "learning_rate": 1.458149779735683e-06,
      "loss": 0.0881,
      "step": 4210
    },
    {
      "epoch": 18.590308370044053,
      "grad_norm": 0.9851834774017334,
      "learning_rate": 1.4140969162995597e-06,
      "loss": 0.087,
      "step": 4220
    },
    {
      "epoch": 18.634361233480178,
      "grad_norm": 1.057553768157959,
      "learning_rate": 1.3700440528634363e-06,
      "loss": 0.0905,
      "step": 4230
    },
    {
      "epoch": 18.6784140969163,
      "grad_norm": 1.0513136386871338,
      "learning_rate": 1.3259911894273129e-06,
      "loss": 0.0902,
      "step": 4240
    },
    {
      "epoch": 18.722466960352424,
      "grad_norm": 1.0846130847930908,
      "learning_rate": 1.2819383259911897e-06,
      "loss": 0.0863,
      "step": 4250
    },
    {
      "epoch": 18.766519823788546,
      "grad_norm": 1.1799246072769165,
      "learning_rate": 1.237885462555066e-06,
      "loss": 0.0848,
      "step": 4260
    },
    {
      "epoch": 18.81057268722467,
      "grad_norm": 1.049073338508606,
      "learning_rate": 1.1938325991189428e-06,
      "loss": 0.0867,
      "step": 4270
    },
    {
      "epoch": 18.854625550660792,
      "grad_norm": 1.1107569932937622,
      "learning_rate": 1.1497797356828194e-06,
      "loss": 0.095,
      "step": 4280
    },
    {
      "epoch": 18.898678414096917,
      "grad_norm": 1.2207953929901123,
      "learning_rate": 1.1057268722466961e-06,
      "loss": 0.0964,
      "step": 4290
    },
    {
      "epoch": 18.94273127753304,
      "grad_norm": 1.0704532861709595,
      "learning_rate": 1.0616740088105727e-06,
      "loss": 0.0889,
      "step": 4300
    },
    {
      "epoch": 18.986784140969164,
      "grad_norm": 1.0207194089889526,
      "learning_rate": 1.0176211453744495e-06,
      "loss": 0.0856,
      "step": 4310
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.0902256891131401,
      "eval_runtime": 28.0787,
      "eval_samples_per_second": 7.194,
      "eval_steps_per_second": 0.926,
      "step": 4313
    },
    {
      "epoch": 19.030837004405285,
      "grad_norm": 1.0758317708969116,
      "learning_rate": 9.73568281938326e-07,
      "loss": 0.0908,
      "step": 4320
    },
    {
      "epoch": 19.07488986784141,
      "grad_norm": 1.235098123550415,
      "learning_rate": 9.295154185022027e-07,
      "loss": 0.0842,
      "step": 4330
    },
    {
      "epoch": 19.11894273127753,
      "grad_norm": 1.132944107055664,
      "learning_rate": 8.854625550660793e-07,
      "loss": 0.0861,
      "step": 4340
    },
    {
      "epoch": 19.162995594713657,
      "grad_norm": 1.0725454092025757,
      "learning_rate": 8.414096916299561e-07,
      "loss": 0.0925,
      "step": 4350
    },
    {
      "epoch": 19.207048458149778,
      "grad_norm": 1.0579134225845337,
      "learning_rate": 7.973568281938327e-07,
      "loss": 0.0855,
      "step": 4360
    },
    {
      "epoch": 19.251101321585903,
      "grad_norm": 1.099460244178772,
      "learning_rate": 7.533039647577093e-07,
      "loss": 0.0892,
      "step": 4370
    },
    {
      "epoch": 19.295154185022028,
      "grad_norm": 1.116776466369629,
      "learning_rate": 7.092511013215859e-07,
      "loss": 0.0896,
      "step": 4380
    },
    {
      "epoch": 19.33920704845815,
      "grad_norm": 1.2576860189437866,
      "learning_rate": 6.651982378854627e-07,
      "loss": 0.0916,
      "step": 4390
    },
    {
      "epoch": 19.383259911894275,
      "grad_norm": 1.0132771730422974,
      "learning_rate": 6.211453744493393e-07,
      "loss": 0.0871,
      "step": 4400
    },
    {
      "epoch": 19.427312775330396,
      "grad_norm": 1.1192271709442139,
      "learning_rate": 5.770925110132159e-07,
      "loss": 0.085,
      "step": 4410
    },
    {
      "epoch": 19.47136563876652,
      "grad_norm": 1.149477481842041,
      "learning_rate": 5.330396475770926e-07,
      "loss": 0.0876,
      "step": 4420
    },
    {
      "epoch": 19.515418502202643,
      "grad_norm": 1.156192421913147,
      "learning_rate": 4.889867841409692e-07,
      "loss": 0.0846,
      "step": 4430
    },
    {
      "epoch": 19.559471365638768,
      "grad_norm": 1.0374411344528198,
      "learning_rate": 4.4493392070484585e-07,
      "loss": 0.0934,
      "step": 4440
    },
    {
      "epoch": 19.60352422907489,
      "grad_norm": 1.0150024890899658,
      "learning_rate": 4.008810572687225e-07,
      "loss": 0.0868,
      "step": 4450
    },
    {
      "epoch": 19.647577092511014,
      "grad_norm": 1.1350650787353516,
      "learning_rate": 3.568281938325992e-07,
      "loss": 0.0896,
      "step": 4460
    },
    {
      "epoch": 19.691629955947135,
      "grad_norm": 1.1084022521972656,
      "learning_rate": 3.127753303964758e-07,
      "loss": 0.0942,
      "step": 4470
    },
    {
      "epoch": 19.73568281938326,
      "grad_norm": 1.2393559217453003,
      "learning_rate": 2.6872246696035244e-07,
      "loss": 0.092,
      "step": 4480
    },
    {
      "epoch": 19.779735682819382,
      "grad_norm": 1.138512372970581,
      "learning_rate": 2.246696035242291e-07,
      "loss": 0.0918,
      "step": 4490
    },
    {
      "epoch": 19.823788546255507,
      "grad_norm": 1.1212341785430908,
      "learning_rate": 1.8061674008810574e-07,
      "loss": 0.0916,
      "step": 4500
    },
    {
      "epoch": 19.86784140969163,
      "grad_norm": 1.1295777559280396,
      "learning_rate": 1.365638766519824e-07,
      "loss": 0.089,
      "step": 4510
    },
    {
      "epoch": 19.911894273127754,
      "grad_norm": 1.3091360330581665,
      "learning_rate": 9.251101321585904e-08,
      "loss": 0.093,
      "step": 4520
    },
    {
      "epoch": 19.955947136563875,
      "grad_norm": 0.9953244924545288,
      "learning_rate": 4.8458149779735684e-08,
      "loss": 0.0869,
      "step": 4530
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.210634469985962,
      "learning_rate": 4.405286343612335e-09,
      "loss": 0.0924,
      "step": 4540
    },
    {
      "epoch": 20.0,
      "eval_loss": 0.09008360654115677,
      "eval_runtime": 27.9189,
      "eval_samples_per_second": 7.235,
      "eval_steps_per_second": 0.931,
      "step": 4540
    }
  ],
  "logging_steps": 10,
  "max_steps": 4540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.350970015720407e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
